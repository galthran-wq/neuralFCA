{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "dUEvmHBsu8J0"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "sB1UqaW_u8J3",
        "outputId": "863a82d3-f3e9-49f6-b569-079be9ee7b86"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>All residents asked to 'shelter in place' are ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  target\n",
              "0  Our Deeds are the Reason of this #earthquake M...       1\n",
              "1             Forest fire near La Ronge Sask. Canada       1\n",
              "2  All residents asked to 'shelter in place' are ...       1\n",
              "3  13,000 people receive #wildfires evacuation or...       1\n",
              "4  Just got sent this photo from Ruby #Alaska as ...       1"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_csv(\"./data/tweets_train.csv\").drop(columns=['id','keyword', 'location'])\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.compose import make_column_transformer\n",
        "from sklearn.preprocessing import KBinsDiscretizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "features = 'text'\n",
        "y_feat = 'remainder__target'\n",
        "preprocessing_pipeline = make_column_transformer(\n",
        "    (CountVectorizer(lowercase=True, stop_words=\"english\", max_features=1000), features),\n",
        "    remainder=\"passthrough\",\n",
        ")\n",
        "lr = LogisticRegression(max_iter=500)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9aa70cd4112049d684336fc98f5ccbfc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from sklearn.model_selection import KFold\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "from neural_fca import NeuralFCA\n",
        "\n",
        "kf = KFold(n_splits=5)\n",
        "cv_f1_scores = []\n",
        "lr_cv_f1_scores = []\n",
        "fcas = []\n",
        "\n",
        "for train, test in tqdm(kf.split(df)):\n",
        "    df_train = df.iloc[train, :]\n",
        "    df_test= df.iloc[test, :]\n",
        "\n",
        "    preprocessing_pipeline.fit(df_train)\n",
        "\n",
        "    df_train2 = pd.DataFrame(\n",
        "        preprocessing_pipeline.transform(df_train).toarray(),\n",
        "        columns=preprocessing_pipeline.get_feature_names_out()\n",
        "    )\n",
        "    df_test2 = pd.DataFrame(\n",
        "        preprocessing_pipeline.transform(df_test).toarray(),\n",
        "        columns=preprocessing_pipeline.get_feature_names_out()\n",
        "    )\n",
        "\n",
        "    X_train = df_train2.drop(columns=y_feat)\n",
        "    y_train = df_train2[y_feat]\n",
        "    X_test = df_test2.drop(columns=y_feat)\n",
        "    y_test = df_test2[y_feat]\n",
        "\n",
        "    topk_words = np.argsort(-lr.coef_[0])[:100]\n",
        "    X_train_topk = X_train.iloc[:, topk_words].astype(\"bool\")\n",
        "    X_test_topk = X_test.iloc[:, topk_words].astype(\"bool\")\n",
        "    X_test_topk['dummy'] = True\n",
        "    X_train_topk['dummy'] = True\n",
        "    X_train_topk.index = X_train.index.map(str)\n",
        "    X_test_topk.index = X_test.index.map(str)\n",
        "    fca = NeuralFCA(best_concepts_fraction=0.5).fit(X_train_topk, y_train)\n",
        "    cv_f1_scores.append(fca.score(X_test_topk, y_test))\n",
        "    fcas.append(fca)\n",
        "\n",
        "    lr.fit(X_train_topk, y_train)\n",
        "    lr_cv_f1_scores.append(\n",
        "        f1_score(lr.predict(X_test_topk), y_test)\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[0.0, 0.19452054794520546, 0.0, 0.0, 0.0]"
            ]
          },
          "execution_count": 101,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cv_f1_scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[0.2728512960436562,\n",
              " 0.21151271753681392,\n",
              " 0.15587529976019185,\n",
              " 0.13783403656821377,\n",
              " 0.1625]"
            ]
          },
          "execution_count": 102,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "lr_cv_f1_scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.03890410958904109"
            ]
          },
          "execution_count": 103,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.mean(cv_f1_scores)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
